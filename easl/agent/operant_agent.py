__author__ = 'Dennis'

from agent import Agent


class WorkingMemory(object):
    """
    "The working memory module holds a collection of time-labeled
         predicates describing the rat's current perceptions and actions
         and those of the recent past."

    Attributes
    ----------
    memory : {number: ([predicates], [predicates])}
         Age, sensory predicates, and action predicates at the current,
         and recent, instant(s).
    """
    def __init__(self):
        self._MAX_AGE = 8

        self.memory = {}
        self.__init_now()

    def __init_now(self):
        self.memory[0] = ([], [])

    def age(self):
        """
        Updates all memory units' age by one time step.
        """
        # TODO: Check type of predicate? (different max ages)
        # Create a new representation with all ages incremented.
        aged = {}
        for m in self.memory:
            aged[m+1] = self.memory[m]

        self.memory = aged
        # Prepare the current time slot
        self.__init_now()

    def add_sensory(self, predicate):
        """
        Adds a sensory predicate.
        """
        self.memory[0][0].append(predicate)

    def add_action(self, action):
        """
        Adds an action predicate.
        """
        self.memory[0][1].append(action)


class OperantConditioningAgent(Agent):
    # TODO(Dennis): Implement.
    """
    Uses operant conditioning based learning.

    Primary reinforcers can reinforce behavior without the animal having had
    any prior experience with them (e.g., food, water).

    Needs
     - link between action predicates and actual actions

    References
    ----------
    .. [1] "Operant Conditioning in Skinnerbots,"
           David S. Touretzky & Lisa M. Saksida.
    """
    # TODO(Question): Where to get primary reinforcers?
    """
    Acquiring Conditioned Reinforcers

    "If the skinnerbot could find a way to make HEAR(pump) be true, then
     predictor #3 suggests it could get water whenever it wanted.
     So HEAR(pump) becomes a secondary reinforcer, and the skinnerbot begins
     trying out theories of what causes the pump to run."

    I.e. if a predictor has a sensory predicate, that sensory predicate
    becomes a reinforcer itself.
    """
    """
    Predictor: conjunction -> reinforcer w/ probability

    "During learning, conjunctions that are sufficiently well correlated with
     rewards generate "predictors," i.e., rules for predicting reward.
     These may displace earlier predictors that have not performed as well.
     To allow for the effects of noise, predictors are not replaced until they
     have a reasonably high application count (so their success rate can be
     accurately estimated) and their replacement has a significantly higher success
     rate."
    """
    """
    Action Generation

    "To generate behavior, we look for predictors that can be satisfied by the
    rat's taking some action currently available to it."

    "Predictors in our model can be divided into two classes: those that contain
     an action term, and those that do not.
     Since the former can  e satisfied by executing the action, they are
     instrumental rules.
     The latter, such as predictor #2 above, may be viewed as Pavlovian rules:
     they represent an association between stimuli.
     The response generated by this association would have to be innate and
     hardwired."

    "There is also some randomness in the action selection mechanism, to
    facilitate exploration."

    Use a different mechanism for exploration?
    """
    """
    Action Selection

    "If it finds a predictor where all but one of the predicates is currently
     true (i.e., matches an item in working memory), and the last one can be
     made true by taking some action that is presently available, then it will
    select that action with high probability."
    """
    # TODO: When to create new reinforcer?
    # TODO: When new reinforcer, create new predictor.
    """
    Predictor Creation and Deletion

    "New predictors for a given reinforcer are created only when that reinforcer
     has just been received and the reward counts updated.
     At that point, the program can check candidate predictors against its
     working memory, so that it only constructs predictors that would have
     predicted the reward it just got."
    "Furthermore, in order for new predictors to be created the reward must
     either have been unexpected, meaning the current set of predictors is
     incomplete, or there must have been at least one false prediction since
     the last reward was encountered, meaning there is an erroneous predictor,
     one that is not specific enough to accurately express the reward
     contingencies."

    "New predictors are created from the b est-scoring conjunctions currently
     maintained for that reinforcer.
     If several conjunctions are tied for top score, the ones with the fewest
     number of terms are selected."
    "If there are still several candidates, two are chosen at random to become
     new predictors." (Enforces exploration.)

    "Two numerical measures are used to assign scores to conjunctions and
     predictors: merit and demerit.
     They estimate the lower and upper bounds, respectively, on the true reward
     rate based on the number of examples seen so far."

    "Let :math:`n` be the number of times a conjunction has been observed to be
     true, and :math:`r` the number of times the reinforcer was received on the
     subsequent time step.
     Merit and demerit are defined as:"

    .. math:: M(r, n) = \frac{r}{n} \mdot \max(0.2, 1 - \frac{1.175}{n})
    .. math:: M(r, 0) = 1

    .. math:: D(r, n) = \min(1, \frac{r}{n} + \frac{n - r}{0.7n^2})
    .. math:: D(r, 0) = 0

    "As :math:`n` approaches :math:`\inf`, merit and demerit both converge to
     :math:`\frac{r}{n}`, the true reward rate."

    "When creating new predictors, candidate conjunctions are sorted by merit
     rather than raw reward rate to give greater weight to conjunctions that
     have been sampled more heavily.
     When deleting predictors, demerit is used, so the program is conservative
     in its judgements and does not delete too quickly."

    "Predictors are deleted in three circumstances.

     First, if the predictor has just given a false alarm, it may be deleted if
     its demerit is below a certain minimum value. (Remove bad predictors.)
     Second, if a reinforcer has just been correctly predicted, the predictor
     may be deleted if its demerit is less than the highest merit of any other
     successful predictor for that reinforcer. (Substitution for better one.)
     Finally, a predictor will b e deleted if there is another predictor whose
     antecedent uses a strict subset of the terms in this predictor's
     conjunction, whose merit is nearly as good, and whose number of trials is
     sufficiently high that there is reasonable confidence that the two
     predictors are equivalent.
    """

    """
    "The algorithm for inferring reinforcement contingencies operates on a
     collection of slightly more abstract items called temporal predicates.
     These are derived from working memory elements by replacing numeric
     time tags with symbolic labels."
    """
    _PREV = -1
    _NOW = 0
    _FUT = 1

    def __init__(self):
        """
        Attributes
        ----------
        reinforcers : [ {predicate: [conjunction: (sat, fol)]} ]
            "Conditioned reinforcers are stimuli that become associated with food or
             water (or some other innate reward (even exercise), and serve as a signal
             that the reward is coming, thereby eliminating the gap between the desired
             action and the reinforcement signal."
            "In order to extract this information from its experience of the
             world, the program maintains two tables for each reinforcer.
             One counts the number of times each conjunction has been satisfied
             since that reinforcer was acquired; the other table counts the
             number of times a conjunction's occurrence has been followed on
             the next time step by the reinforcer.
        predictors : [(reinforcer, conjunction, probability)]
            All current predictors.
        """
        super(OperantConditioningAgent, self).__init__()
        self.memory = WorkingMemory()

        self.reinforcers = []
        self.predictors = []

        self.observations = []

    def init_internal(self):
        # Create action and observable predicates
        # Initialize the conjunctions
        pass

    def sense(self, observation):
        # Store observations for later conversion
        self.observations.append(observation)

    def act(self):
        # TODO(Dennis): Implement.
        # Age memory.
        self.memory.age()
        # Turn observations into predicates
        self.__store_observations()

        # Do stuff that leads to selecting actions
        # ...
        self.__generate_predictors()

        actions = []  # placeholder
        # Add actions as predicates
        for action in actions:
            self.memory.add_action(action)

        return actions

    def __store_observations(self):
        """
        Stores all observations as sensory predicates.
        """
        for observation in self.observations:
            self.memory.add_sensory(observation)

    def make_conjuctions(self):
        """
        Conjunctions are constructed incrementally by combining a pool of
        currently "best" conjunctions (starting with the null conjunction)
        with a pool of "best" predicates.

        A "best" conjunction is one whose reward rate is at least one standard
        deviation above the mean rate, or whose reward count is at least one
        standard deviation above the mean count. Both tests are necessary.
        """
